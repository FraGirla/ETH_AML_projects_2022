{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tslearn.utils import to_time_series_dataset\n",
    "import biosppy.signals.ecg as ecg\n",
    "import matplotlib.pyplot as plt\n",
    "import neurokit2 as nk\n",
    "import heartpy as hp\n",
    "from statistics import mean\n",
    "import functions\n",
    "from multiprocessing import Pool\n",
    "from datetime import time\n",
    "from pandarallel import pandarallel\n",
    "import functions\n",
    "import scipy\n",
    "import math\n",
    "import pywt\n",
    "import operator\n",
    "from functions import *\n",
    "import itertools\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"\"\n",
    "raw = folder + \"raw_data/\"\n",
    "x_train = pd.read_csv('x_train_preprocess.csv')\n",
    "x_test = pd.read_csv('x_test_preprocess.csv')\n",
    "y_train = pd.read_csv(raw + 'y_train.csv', index_col=['id'])\n",
    "x_train = x_train.fillna(0)\n",
    "x_test = x_test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5117 entries, 0 to 5116\n",
      "Columns: 555 entries, Unnamed: 0 to nk_feat_13\n",
      "dtypes: float64(554), int64(1)\n",
      "memory usage: 21.7 MB\n"
     ]
    }
   ],
   "source": [
    "x_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = SelectKBest(score_func=f_classif, k=300)\n",
    "selector.fit(np.array(x_train), np.array(y_train).squeeze())\n",
    "cols = selector.get_support(indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train= x_train.iloc[:,cols]\n",
    "#x_test = x_test.iloc[:,cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature reduction with pca\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=100)\n",
    "pca.fit(x_train)\n",
    "x_train = pca.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/francescog/Scaricati/AML_Pr_2/venv/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 555 features, but MinMaxScaler is expecting 100 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [46], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m scaler \u001b[39m=\u001b[39m MinMaxScaler()\n\u001b[1;32m      6\u001b[0m x_train \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39mfit_transform(x_train)\n\u001b[0;32m----> 7\u001b[0m x_test \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39;49mtransform(x_test)\n",
      "File \u001b[0;32m~/Scaricati/AML_Pr_2/venv/lib/python3.8/site-packages/sklearn/preprocessing/_data.py:499\u001b[0m, in \u001b[0;36mMinMaxScaler.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[39m\"\"\"Scale features of X according to feature_range.\u001b[39;00m\n\u001b[1;32m    486\u001b[0m \n\u001b[1;32m    487\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[39m    Transformed data.\u001b[39;00m\n\u001b[1;32m    496\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    497\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m--> 499\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m    500\u001b[0m     X,\n\u001b[1;32m    501\u001b[0m     copy\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcopy,\n\u001b[1;32m    502\u001b[0m     dtype\u001b[39m=\u001b[39;49mFLOAT_DTYPES,\n\u001b[1;32m    503\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    504\u001b[0m     reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    505\u001b[0m )\n\u001b[1;32m    507\u001b[0m X \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscale_\n\u001b[1;32m    508\u001b[0m X \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_\n",
      "File \u001b[0;32m~/Scaricati/AML_Pr_2/venv/lib/python3.8/site-packages/sklearn/base.py:600\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    597\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    599\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m--> 600\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_n_features(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[1;32m    602\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/Scaricati/AML_Pr_2/venv/lib/python3.8/site-packages/sklearn/base.py:400\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \u001b[39mif\u001b[39;00m n_features \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 400\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    401\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX has \u001b[39m\u001b[39m{\u001b[39;00mn_features\u001b[39m}\u001b[39;00m\u001b[39m features, but \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    402\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mis expecting \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_\u001b[39m}\u001b[39;00m\u001b[39m features as input.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    403\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 555 features, but MinMaxScaler is expecting 100 features as input."
     ]
    }
   ],
   "source": [
    "#scale data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "clf = xgb.XGBClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6824237860812133\n",
      "0.013742198499160979\n"
     ]
    }
   ],
   "source": [
    "#cross validation score\n",
    "scores = cross_val_score(clf, x_train, np.ravel(y_train), cv=10, scoring='f1_micro', n_jobs=-1)\n",
    "print(scores.mean())\n",
    "print(scores.std())\n",
    "#0.6994274400684931 StandardScaler\n",
    "#0.6996231347847358 MinMaxScaler"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "57fe57f2cdf78f92aee3d99b2913a1180873ba5e033bb181342afa13c0f35957"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
